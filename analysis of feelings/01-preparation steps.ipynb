{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jones Granatyr Classroom - https://www.udemy.com/mineracao-de-emocao-em-textos-com-python-e-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download() # update packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Mr. Green killed Colonel Mustard in the study with the candlestick. Mr. Green is not a very nice fellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr', 'Green killed Colonel Mustard in the study with the candlestick', 'Mr', 'Green is not a very nice fellow']\n"
     ]
    }
   ],
   "source": [
    "print(text.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = nltk.tokenize.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr. Green killed Colonel Mustard in the study with the candlestick.', 'Mr. Green is not a very nice fellow']\n"
     ]
    }
   ],
   "source": [
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Green', 'killed', 'Colonel', 'Mustard', 'in', 'the', 'study', 'with', 'the', 'candlestick', '.', 'Mr.', 'Green', 'is', 'not', 'a', 'very', 'nice', 'fellow']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows the classes of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mr.', 'NNP'), ('Green', 'NNP'), ('killed', 'VBD'), ('Colonel', 'NNP'), ('Mustard', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('study', 'NN'), ('with', 'IN'), ('the', 'DT'), ('candlestick', 'NN'), ('.', '.'), ('Mr.', 'NNP'), ('Green', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('very', 'RB'), ('nice', 'JJ'), ('fellow', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Mr./NNP)\n",
      "  (PERSON Green/NNP)\n",
      "  killed/VBD\n",
      "  (ORGANIZATION Colonel/NNP Mustard/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  study/NN\n",
      "  with/IN\n",
      "  the/DT\n",
      "  candlestick/NN\n",
      "  ./.\n",
      "  (PERSON Mr./NNP Green/NNP)\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  a/DT\n",
      "  very/RB\n",
      "  nice/JJ\n",
      "  fellow/NN)\n"
     ]
    }
   ],
   "source": [
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portuguese: https://www.nltk.org/howto/portuguese_en.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences to train feelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia está muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('eu sou admirada por muitos', 'alegria')\n"
     ]
    }
   ],
   "source": [
    "print(base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do', 'e', 'estou', 'esta', 'esta',\n",
    "             'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa', 'o', 'outro', 'para', 'que', 'sem', 'talvez', 'tem', 'tendo',\n",
    "             'tenha', 'teve', 'tive', 'todo', 'um', 'uma', 'umas', 'uns', 'vou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texto):\n",
    "\tfrases = []\n",
    "\n",
    "\tfor (palavras, emocao) in texto:\n",
    "\t\tsemstop = [p for p in palavras.split() if p not in stopwords]\n",
    "\t\tfrases.append((semstop, emocao))\n",
    "\treturn frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['eu', 'sou', 'admirada', 'por', 'muitos'], 'alegria'), (['me', 'sinto', 'completamente', 'amado'], 'alegria'), (['amar', 'maravilhoso'], 'alegria'), (['me', 'sentindo', 'animado', 'novamente'], 'alegria'), (['eu', 'bem', 'hoje'], 'alegria'), (['belo', 'dia', 'dirigir', 'carro', 'novo'], 'alegria'), (['dia', 'está', 'bonito'], 'alegria'), (['contente', 'com', 'resultado', 'teste', 'fiz', 'dia', 'ontem'], 'alegria'), (['amor', 'lindo'], 'alegria'), (['amizade', 'amor', 'vai', 'durar', 'sempre'], 'alegria'), (['amedrontado'], 'medo'), (['ele', 'me', 'ameacando', 'dias'], 'medo'), (['isso', 'me', 'deixa', 'apavorada'], 'medo'), (['este', 'lugar', 'apavorante'], 'medo'), (['se', 'perdermos', 'jogo', 'seremos', 'eliminados', 'isso', 'me', 'deixa', 'com', 'pavor'], 'medo'), (['tome', 'cuidado', 'com', 'lobisomem'], 'medo'), (['se', 'eles', 'descobrirem', 'estamos', 'encrencados'], 'medo'), (['tremendo', 'medo'], 'medo'), (['eu', 'tenho', 'medo', 'dele'], 'medo'), (['com', 'medo', 'resultado', 'dos', 'meus', 'testes'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(remove_stopwords(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "stopwords_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stopwords_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admirada', 'muitos'], 'alegria'), (['sinto', 'completamente', 'amado'], 'alegria'), (['amar', 'maravilhoso'], 'alegria'), (['sentindo', 'animado', 'novamente'], 'alegria'), (['bem', 'hoje'], 'alegria'), (['belo', 'dia', 'dirigir', 'carro', 'novo'], 'alegria'), (['dia', 'bonito'], 'alegria'), (['contente', 'resultado', 'teste', 'fiz', 'dia', 'ontem'], 'alegria'), (['amor', 'lindo'], 'alegria'), (['amizade', 'amor', 'vai', 'durar', 'sempre'], 'alegria'), (['amedrontado'], 'medo'), (['ameacando', 'dias'], 'medo'), (['deixa', 'apavorada'], 'medo'), (['lugar', 'apavorante'], 'medo'), (['perdermos', 'outro', 'jogo', 'eliminados', 'deixa', 'pavor'], 'medo'), (['tome', 'cuidado', 'lobisomem'], 'medo'), (['descobrirem', 'encrencados'], 'medo'), (['tremendo', 'medo'], 'medo'), (['medo'], 'medo'), (['medo', 'resultado', 'testes'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(texto):\n",
    "\tfrases = []\n",
    "\n",
    "\tfor (palavras, emocao) in texto:\n",
    "\t\tsemstop = [p for p in palavras.split() if p not in stopwords_nltk]\n",
    "\t\tfrases.append((semstop, emocao))\n",
    "\treturn frases\n",
    "\n",
    "print(remove_stopwords(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming - radical of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicastemmer(texto):\n",
    "\tstemmer = nltk.stem.RSLPStemmer()\n",
    "\tfrasesstemming = []\n",
    "\t\n",
    "\tfor (palavras, emocao) in texto:\n",
    "\t\tcomstemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwords_nltk]\n",
    "\t\tfrasesstemming.append((comstemming, emocao))\n",
    "\n",
    "\treturn frasesstemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admir', 'muit'], 'alegria'), (['sint', 'complet', 'am'], 'alegria'), (['am', 'maravilh'], 'alegria'), (['sent', 'anim', 'nov'], 'alegria'), (['bem', 'hoj'], 'alegria'), (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'), (['dia', 'bonit'], 'alegria'), (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'), (['am', 'lind'], 'alegria'), (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'), (['amedront'], 'medo'), (['ameac', 'dia'], 'medo'), (['deix', 'apavor'], 'medo'), (['lug', 'apavor'], 'medo'), (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'), (['tom', 'cuid', 'lobisom'], 'medo'), (['descobr', 'encrenc'], 'medo'), (['trem', 'med'], 'medo'), (['med'], 'medo'), (['med', 'result', 'test'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "frasescomstemming = aplicastemmer(base)\n",
    "print(frasescomstemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing of all words treated from the base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_palavras(frases):\n",
    "\ttodas_palavras = []\n",
    "\tfor (palavras, emocao) in frases:\n",
    "\t\ttodas_palavras.extend(palavras)\n",
    "\treturn todas_palavras\n",
    "\n",
    "palavras = busca_palavras(frasescomstemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admir', 'muit', 'sint', 'complet', 'am', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'nov', 'dia', 'bonit', 'cont', 'result', 'test', 'fiz', 'dia', 'ont', 'am', 'lind', 'amizad', 'am', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'dia', 'deix', 'apavor', 'lug', 'apavor', 'perd', 'outr', 'jog', 'elimin', 'deix', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med', 'med', 'med', 'result', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('am', 4), ('dia', 4), ('med', 3), ('nov', 2), ('result', 2), ('test', 2), ('deix', 2), ('apavor', 2), ('admir', 1), ('muit', 1), ('sint', 1), ('complet', 1), ('maravilh', 1), ('sent', 1), ('anim', 1), ('bem', 1), ('hoj', 1), ('bel', 1), ('dirig', 1), ('carr', 1), ('bonit', 1), ('cont', 1), ('fiz', 1), ('ont', 1), ('lind', 1), ('amizad', 1), ('vai', 1), ('dur', 1), ('sempr', 1), ('amedront', 1), ('ameac', 1), ('lug', 1), ('perd', 1), ('outr', 1), ('jog', 1), ('elimin', 1), ('pav', 1), ('tom', 1), ('cuid', 1), ('lobisom', 1), ('descobr', 1), ('encrenc', 1), ('trem', 1)]\n"
     ]
    }
   ],
   "source": [
    "def buscafrequencia(palavras):\n",
    "\tpalavras = nltk.FreqDist(palavras)\n",
    "\treturn palavras\n",
    "\n",
    "frequencia = buscafrequencia(palavras)\n",
    "print(frequencia.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['admir', 'muit', 'sint', 'complet', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'bonit', 'cont', 'result', 'test', 'fiz', 'ont', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'deix', 'apavor', 'lug', 'perd', 'outr', 'jog', 'elimin', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med'])\n"
     ]
    }
   ],
   "source": [
    "def busca_palavras_unicas(frequencia):\n",
    "\tfreq = frequencia.keys()\n",
    "\treturn freq\n",
    "\n",
    "palavras_unicas = busca_palavras_unicas(frequencia)\n",
    "print(palavras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of words from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'admir': False, 'muit': False, 'sint': False, 'complet': False, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': True, 'bem': False, 'hoj': False, 'bel': False, 'dia': True, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}\n"
     ]
    }
   ],
   "source": [
    "def extrator_palavras(documento):\n",
    "\tdoc = set(documento)\n",
    "\tcaracteristicas = {}\n",
    "\tfor palavras in palavras_unicas:\n",
    "\t\tcaracteristicas['%s' % palavras] = (palavras in doc)\n",
    "\treturn caracteristicas\n",
    "\n",
    "caracteristicas_frase = extrator_palavras(['am', 'nov', 'dia']) \n",
    "print(caracteristicas_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of words from all phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['admir', 'muit'], 'alegria'), (['sint', 'complet', 'am'], 'alegria'), (['am', 'maravilh'], 'alegria'), (['sent', 'anim', 'nov'], 'alegria'), (['bem', 'hoj'], 'alegria'), (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'), (['dia', 'bonit'], 'alegria'), (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'), (['am', 'lind'], 'alegria'), (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'), (['amedront'], 'medo'), (['ameac', 'dia'], 'medo'), (['deix', 'apavor'], 'medo'), (['lug', 'apavor'], 'medo'), (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'), (['tom', 'cuid', 'lobisom'], 'medo'), (['descobr', 'encrenc'], 'medo'), (['trem', 'med'], 'medo'), (['med'], 'medo'), (['med', 'result', 'test'], 'medo')]\n"
     ]
    }
   ],
   "source": [
    "print(frasescomstemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa = nltk.classify.apply_features(extrator_palavras, frasescomstemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ({'admir': False, 'muit': False, 'sint': True, 'complet': True, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(base_completa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of base with feeling of joy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria')\n"
     ]
    }
   ],
   "source": [
    "print(base_completa[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of base with feeling of fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'admir': False, 'muit': False, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': True, 'cuid': True, 'lobisom': True, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'medo')\n"
     ]
    }
   ],
   "source": [
    "print(base_completa[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
